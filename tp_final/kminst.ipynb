{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on MNIST CNN from Keras' examples: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py (MIT License)\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://paperswithcode.com/dataset/kuzushiji-49\n",
    "https://github.com/rois-codh/kmnist\n",
    "\n",
    "['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
    "'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
    "'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
    "'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz'],\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 49\n",
    "epochs = 250\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "\n",
    "# Load the data\n",
    "x_train = load('k49-train-imgs.npz')\n",
    "x_test = load('k49-test-imgs.npz')\n",
    "y_train = load('k49-train-labels.npz')\n",
    "y_test = load('k49-test-labels.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232365 train samples, 38547 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('{} train samples, {} test samples'.format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 89ms/step - accuracy: 0.0306 - loss: 3.8790 - val_accuracy: 0.0823 - val_loss: 3.8419\n",
      "Epoch 2/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.0648 - loss: 3.8220 - val_accuracy: 0.1346 - val_loss: 3.7623\n",
      "Epoch 3/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.0989 - loss: 3.7273 - val_accuracy: 0.1864 - val_loss: 3.6266\n",
      "Epoch 4/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 96ms/step - accuracy: 0.1447 - loss: 3.5729 - val_accuracy: 0.2493 - val_loss: 3.4329\n",
      "Epoch 5/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 96ms/step - accuracy: 0.1948 - loss: 3.3681 - val_accuracy: 0.3009 - val_loss: 3.2186\n",
      "Epoch 6/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 96ms/step - accuracy: 0.2374 - loss: 3.1717 - val_accuracy: 0.3298 - val_loss: 3.0302\n",
      "Epoch 7/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 96ms/step - accuracy: 0.2732 - loss: 3.0041 - val_accuracy: 0.3528 - val_loss: 2.8797\n",
      "Epoch 8/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3032 - loss: 2.8590 - val_accuracy: 0.3702 - val_loss: 2.7584\n",
      "Epoch 9/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 97ms/step - accuracy: 0.3257 - loss: 2.7481 - val_accuracy: 0.3840 - val_loss: 2.6586\n",
      "Epoch 10/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3460 - loss: 2.6469 - val_accuracy: 0.3963 - val_loss: 2.5768\n",
      "Epoch 11/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3632 - loss: 2.5763 - val_accuracy: 0.4089 - val_loss: 2.5048\n",
      "Epoch 12/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3756 - loss: 2.5029 - val_accuracy: 0.4193 - val_loss: 2.4438\n",
      "Epoch 13/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3898 - loss: 2.4475 - val_accuracy: 0.4291 - val_loss: 2.3885\n",
      "Epoch 14/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3991 - loss: 2.4032 - val_accuracy: 0.4380 - val_loss: 2.3422\n",
      "Epoch 15/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 98ms/step - accuracy: 0.4094 - loss: 2.3571 - val_accuracy: 0.4465 - val_loss: 2.2998\n",
      "Epoch 16/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.4177 - loss: 2.3171 - val_accuracy: 0.4548 - val_loss: 2.2632\n",
      "Epoch 17/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 97ms/step - accuracy: 0.4280 - loss: 2.2708 - val_accuracy: 0.4619 - val_loss: 2.2285\n",
      "Epoch 18/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 98ms/step - accuracy: 0.4339 - loss: 2.2503 - val_accuracy: 0.4675 - val_loss: 2.2010\n",
      "Epoch 19/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 97ms/step - accuracy: 0.4415 - loss: 2.2180 - val_accuracy: 0.4740 - val_loss: 2.1723\n",
      "Epoch 20/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 97ms/step - accuracy: 0.4472 - loss: 2.1913 - val_accuracy: 0.4784 - val_loss: 2.1457\n",
      "Epoch 21/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4518 - loss: 2.1713 - val_accuracy: 0.4837 - val_loss: 2.1231\n",
      "Epoch 22/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4592 - loss: 2.1438 - val_accuracy: 0.4882 - val_loss: 2.1016\n",
      "Epoch 23/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4610 - loss: 2.1256 - val_accuracy: 0.4919 - val_loss: 2.0820\n",
      "Epoch 24/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 97ms/step - accuracy: 0.4659 - loss: 2.1068 - val_accuracy: 0.4954 - val_loss: 2.0631\n",
      "Epoch 25/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4717 - loss: 2.0843 - val_accuracy: 0.4982 - val_loss: 2.0471\n",
      "Epoch 26/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4755 - loss: 2.0711 - val_accuracy: 0.5031 - val_loss: 2.0303\n",
      "Epoch 27/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 98ms/step - accuracy: 0.4799 - loss: 2.0544 - val_accuracy: 0.5065 - val_loss: 2.0152\n",
      "Epoch 28/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4817 - loss: 2.0465 - val_accuracy: 0.5101 - val_loss: 2.0015\n",
      "Epoch 29/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4891 - loss: 2.0191 - val_accuracy: 0.5125 - val_loss: 1.9894\n",
      "Epoch 30/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4880 - loss: 2.0094 - val_accuracy: 0.5168 - val_loss: 1.9736\n",
      "Epoch 31/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4946 - loss: 1.9922 - val_accuracy: 0.5200 - val_loss: 1.9598\n",
      "Epoch 32/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4951 - loss: 1.9844 - val_accuracy: 0.5233 - val_loss: 1.9480\n",
      "Epoch 33/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5003 - loss: 1.9672 - val_accuracy: 0.5257 - val_loss: 1.9378\n",
      "Epoch 34/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5017 - loss: 1.9568 - val_accuracy: 0.5291 - val_loss: 1.9266\n",
      "Epoch 35/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5041 - loss: 1.9502 - val_accuracy: 0.5311 - val_loss: 1.9153\n",
      "Epoch 36/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5064 - loss: 1.9356 - val_accuracy: 0.5346 - val_loss: 1.9060\n",
      "Epoch 37/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5112 - loss: 1.9260 - val_accuracy: 0.5372 - val_loss: 1.8954\n",
      "Epoch 38/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5139 - loss: 1.9110 - val_accuracy: 0.5392 - val_loss: 1.8849\n",
      "Epoch 39/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5145 - loss: 1.8998 - val_accuracy: 0.5408 - val_loss: 1.8760\n",
      "Epoch 40/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5184 - loss: 1.8913 - val_accuracy: 0.5427 - val_loss: 1.8671\n",
      "Epoch 41/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5186 - loss: 1.8876 - val_accuracy: 0.5450 - val_loss: 1.8575\n",
      "Epoch 42/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5213 - loss: 1.8783 - val_accuracy: 0.5473 - val_loss: 1.8482\n",
      "Epoch 43/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5238 - loss: 1.8642 - val_accuracy: 0.5489 - val_loss: 1.8409\n",
      "Epoch 44/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5251 - loss: 1.8551 - val_accuracy: 0.5512 - val_loss: 1.8329\n",
      "Epoch 45/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5275 - loss: 1.8474 - val_accuracy: 0.5530 - val_loss: 1.8249\n",
      "Epoch 46/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5306 - loss: 1.8354 - val_accuracy: 0.5545 - val_loss: 1.8178\n",
      "Epoch 47/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.5323 - loss: 1.8287 - val_accuracy: 0.5570 - val_loss: 1.8082\n",
      "Epoch 48/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5364 - loss: 1.8187 - val_accuracy: 0.5588 - val_loss: 1.8009\n",
      "Epoch 49/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5353 - loss: 1.8165 - val_accuracy: 0.5605 - val_loss: 1.7941\n",
      "Epoch 50/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.5380 - loss: 1.8036 - val_accuracy: 0.5625 - val_loss: 1.7865\n",
      "Epoch 51/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.5410 - loss: 1.7952 - val_accuracy: 0.5637 - val_loss: 1.7785\n",
      "Epoch 52/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5443 - loss: 1.7795 - val_accuracy: 0.5646 - val_loss: 1.7725\n",
      "Epoch 53/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5438 - loss: 1.7815 - val_accuracy: 0.5664 - val_loss: 1.7657\n",
      "Epoch 54/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5466 - loss: 1.7707 - val_accuracy: 0.5670 - val_loss: 1.7588\n",
      "Epoch 55/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5476 - loss: 1.7646 - val_accuracy: 0.5695 - val_loss: 1.7518\n",
      "Epoch 56/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 99ms/step - accuracy: 0.5508 - loss: 1.7539 - val_accuracy: 0.5708 - val_loss: 1.7449\n",
      "Epoch 57/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5506 - loss: 1.7466 - val_accuracy: 0.5719 - val_loss: 1.7383\n",
      "Epoch 58/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5513 - loss: 1.7457 - val_accuracy: 0.5733 - val_loss: 1.7309\n",
      "Epoch 59/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5562 - loss: 1.7295 - val_accuracy: 0.5747 - val_loss: 1.7255\n",
      "Epoch 60/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5576 - loss: 1.7201 - val_accuracy: 0.5763 - val_loss: 1.7191\n",
      "Epoch 61/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5561 - loss: 1.7233 - val_accuracy: 0.5770 - val_loss: 1.7122\n",
      "Epoch 62/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5598 - loss: 1.7143 - val_accuracy: 0.5783 - val_loss: 1.7070\n",
      "Epoch 63/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5624 - loss: 1.6950 - val_accuracy: 0.5804 - val_loss: 1.7001\n",
      "Epoch 64/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5670 - loss: 1.6940 - val_accuracy: 0.5820 - val_loss: 1.6938\n",
      "Epoch 65/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5672 - loss: 1.6847 - val_accuracy: 0.5842 - val_loss: 1.6873\n",
      "Epoch 66/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5669 - loss: 1.6839 - val_accuracy: 0.5852 - val_loss: 1.6810\n",
      "Epoch 67/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.5689 - loss: 1.6749 - val_accuracy: 0.5868 - val_loss: 1.6756\n",
      "Epoch 68/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5708 - loss: 1.6651 - val_accuracy: 0.5875 - val_loss: 1.6713\n",
      "Epoch 69/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5714 - loss: 1.6639 - val_accuracy: 0.5890 - val_loss: 1.6638\n",
      "Epoch 70/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5756 - loss: 1.6490 - val_accuracy: 0.5900 - val_loss: 1.6594\n",
      "Epoch 71/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5740 - loss: 1.6500 - val_accuracy: 0.5907 - val_loss: 1.6529\n",
      "Epoch 72/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5801 - loss: 1.6313 - val_accuracy: 0.5924 - val_loss: 1.6480\n",
      "Epoch 73/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5783 - loss: 1.6317 - val_accuracy: 0.5943 - val_loss: 1.6398\n",
      "Epoch 74/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5799 - loss: 1.6258 - val_accuracy: 0.5953 - val_loss: 1.6350\n",
      "Epoch 75/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5824 - loss: 1.6133 - val_accuracy: 0.5967 - val_loss: 1.6295\n",
      "Epoch 76/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5853 - loss: 1.6078 - val_accuracy: 0.5985 - val_loss: 1.6238\n",
      "Epoch 77/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5866 - loss: 1.6032 - val_accuracy: 0.6000 - val_loss: 1.6188\n",
      "Epoch 78/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5867 - loss: 1.5994 - val_accuracy: 0.6007 - val_loss: 1.6112\n",
      "Epoch 79/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5877 - loss: 1.5938 - val_accuracy: 0.6022 - val_loss: 1.6067\n",
      "Epoch 80/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.5938 - loss: 1.5780 - val_accuracy: 0.6035 - val_loss: 1.6005\n",
      "Epoch 81/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5920 - loss: 1.5721 - val_accuracy: 0.6045 - val_loss: 1.5943\n",
      "Epoch 82/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5951 - loss: 1.5625 - val_accuracy: 0.6062 - val_loss: 1.5892\n",
      "Epoch 83/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5942 - loss: 1.5657 - val_accuracy: 0.6076 - val_loss: 1.5828\n",
      "Epoch 84/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5952 - loss: 1.5549 - val_accuracy: 0.6087 - val_loss: 1.5772\n",
      "Epoch 85/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6002 - loss: 1.5470 - val_accuracy: 0.6097 - val_loss: 1.5717\n",
      "Epoch 86/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 99ms/step - accuracy: 0.6009 - loss: 1.5399 - val_accuracy: 0.6112 - val_loss: 1.5665\n",
      "Epoch 87/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6031 - loss: 1.5328 - val_accuracy: 0.6122 - val_loss: 1.5619\n",
      "Epoch 88/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6023 - loss: 1.5359 - val_accuracy: 0.6141 - val_loss: 1.5549\n",
      "Epoch 89/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6046 - loss: 1.5289 - val_accuracy: 0.6151 - val_loss: 1.5492\n",
      "Epoch 90/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6084 - loss: 1.5125 - val_accuracy: 0.6167 - val_loss: 1.5435\n",
      "Epoch 91/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6111 - loss: 1.5043 - val_accuracy: 0.6176 - val_loss: 1.5381\n",
      "Epoch 92/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6141 - loss: 1.4937 - val_accuracy: 0.6186 - val_loss: 1.5321\n",
      "Epoch 93/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6124 - loss: 1.4943 - val_accuracy: 0.6203 - val_loss: 1.5271\n",
      "Epoch 94/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6121 - loss: 1.4941 - val_accuracy: 0.6222 - val_loss: 1.5218\n",
      "Epoch 95/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6167 - loss: 1.4812 - val_accuracy: 0.6231 - val_loss: 1.5160\n",
      "Epoch 96/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6163 - loss: 1.4781 - val_accuracy: 0.6238 - val_loss: 1.5100\n",
      "Epoch 97/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6179 - loss: 1.4697 - val_accuracy: 0.6256 - val_loss: 1.5048\n",
      "Epoch 98/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6212 - loss: 1.4632 - val_accuracy: 0.6267 - val_loss: 1.4984\n",
      "Epoch 99/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6207 - loss: 1.4564 - val_accuracy: 0.6283 - val_loss: 1.4925\n",
      "Epoch 100/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6269 - loss: 1.4408 - val_accuracy: 0.6293 - val_loss: 1.4874\n",
      "Epoch 101/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6241 - loss: 1.4456 - val_accuracy: 0.6307 - val_loss: 1.4811\n",
      "Epoch 102/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.6283 - loss: 1.4325 - val_accuracy: 0.6316 - val_loss: 1.4766\n",
      "Epoch 103/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6308 - loss: 1.4241 - val_accuracy: 0.6331 - val_loss: 1.4705\n",
      "Epoch 104/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6295 - loss: 1.4252 - val_accuracy: 0.6337 - val_loss: 1.4661\n",
      "Epoch 105/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6306 - loss: 1.4152 - val_accuracy: 0.6353 - val_loss: 1.4598\n",
      "Epoch 106/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6361 - loss: 1.4043 - val_accuracy: 0.6368 - val_loss: 1.4543\n",
      "Epoch 107/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6351 - loss: 1.3977 - val_accuracy: 0.6377 - val_loss: 1.4490\n",
      "Epoch 108/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6385 - loss: 1.3916 - val_accuracy: 0.6397 - val_loss: 1.4431\n",
      "Epoch 109/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6386 - loss: 1.3882 - val_accuracy: 0.6403 - val_loss: 1.4382\n",
      "Epoch 110/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6404 - loss: 1.3821 - val_accuracy: 0.6415 - val_loss: 1.4333\n",
      "Epoch 111/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6409 - loss: 1.3789 - val_accuracy: 0.6423 - val_loss: 1.4282\n",
      "Epoch 112/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6408 - loss: 1.3762 - val_accuracy: 0.6433 - val_loss: 1.4221\n",
      "Epoch 113/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6441 - loss: 1.3693 - val_accuracy: 0.6446 - val_loss: 1.4164\n",
      "Epoch 114/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6475 - loss: 1.3560 - val_accuracy: 0.6458 - val_loss: 1.4113\n",
      "Epoch 115/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6469 - loss: 1.3570 - val_accuracy: 0.6465 - val_loss: 1.4062\n",
      "Epoch 116/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6503 - loss: 1.3472 - val_accuracy: 0.6484 - val_loss: 1.4012\n",
      "Epoch 117/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 104ms/step - accuracy: 0.6509 - loss: 1.3418 - val_accuracy: 0.6500 - val_loss: 1.3949\n",
      "Epoch 118/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 108ms/step - accuracy: 0.6519 - loss: 1.3354 - val_accuracy: 0.6510 - val_loss: 1.3907\n",
      "Epoch 119/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 108ms/step - accuracy: 0.6545 - loss: 1.3302 - val_accuracy: 0.6523 - val_loss: 1.3851\n",
      "Epoch 120/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 108ms/step - accuracy: 0.6537 - loss: 1.3282 - val_accuracy: 0.6533 - val_loss: 1.3794\n",
      "Epoch 121/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.6574 - loss: 1.3113 - val_accuracy: 0.6550 - val_loss: 1.3758\n",
      "Epoch 122/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.6579 - loss: 1.3155 - val_accuracy: 0.6563 - val_loss: 1.3697\n",
      "Epoch 123/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6587 - loss: 1.3127 - val_accuracy: 0.6577 - val_loss: 1.3644\n",
      "Epoch 124/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6632 - loss: 1.2961 - val_accuracy: 0.6589 - val_loss: 1.3594\n",
      "Epoch 125/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6616 - loss: 1.2929 - val_accuracy: 0.6601 - val_loss: 1.3552\n",
      "Epoch 126/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6622 - loss: 1.2908 - val_accuracy: 0.6609 - val_loss: 1.3496\n",
      "Epoch 127/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6648 - loss: 1.2907 - val_accuracy: 0.6621 - val_loss: 1.3445\n",
      "Epoch 128/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6660 - loss: 1.2838 - val_accuracy: 0.6632 - val_loss: 1.3399\n",
      "Epoch 129/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6690 - loss: 1.2764 - val_accuracy: 0.6644 - val_loss: 1.3342\n",
      "Epoch 130/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6690 - loss: 1.2699 - val_accuracy: 0.6649 - val_loss: 1.3306\n",
      "Epoch 131/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6705 - loss: 1.2632 - val_accuracy: 0.6668 - val_loss: 1.3248\n",
      "Epoch 132/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6705 - loss: 1.2637 - val_accuracy: 0.6679 - val_loss: 1.3205\n",
      "Epoch 133/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6744 - loss: 1.2502 - val_accuracy: 0.6690 - val_loss: 1.3159\n",
      "Epoch 134/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6730 - loss: 1.2495 - val_accuracy: 0.6696 - val_loss: 1.3108\n",
      "Epoch 135/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6754 - loss: 1.2450 - val_accuracy: 0.6715 - val_loss: 1.3064\n",
      "Epoch 136/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6747 - loss: 1.2406 - val_accuracy: 0.6723 - val_loss: 1.3017\n",
      "Epoch 137/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6788 - loss: 1.2288 - val_accuracy: 0.6740 - val_loss: 1.2968\n",
      "Epoch 138/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6794 - loss: 1.2248 - val_accuracy: 0.6744 - val_loss: 1.2931\n",
      "Epoch 139/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6819 - loss: 1.2206 - val_accuracy: 0.6756 - val_loss: 1.2881\n",
      "Epoch 140/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6821 - loss: 1.2144 - val_accuracy: 0.6764 - val_loss: 1.2836\n",
      "Epoch 141/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6816 - loss: 1.2200 - val_accuracy: 0.6777 - val_loss: 1.2794\n",
      "Epoch 142/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6838 - loss: 1.2093 - val_accuracy: 0.6788 - val_loss: 1.2746\n",
      "Epoch 143/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6859 - loss: 1.2060 - val_accuracy: 0.6796 - val_loss: 1.2703\n",
      "Epoch 144/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.6847 - loss: 1.2000 - val_accuracy: 0.6809 - val_loss: 1.2665\n",
      "Epoch 145/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6862 - loss: 1.1986 - val_accuracy: 0.6822 - val_loss: 1.2624\n",
      "Epoch 146/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 102ms/step - accuracy: 0.6902 - loss: 1.1885 - val_accuracy: 0.6833 - val_loss: 1.2579\n",
      "Epoch 147/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.6887 - loss: 1.1828 - val_accuracy: 0.6839 - val_loss: 1.2535\n",
      "Epoch 148/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.6895 - loss: 1.1834 - val_accuracy: 0.6852 - val_loss: 1.2500\n",
      "Epoch 149/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6915 - loss: 1.1750 - val_accuracy: 0.6857 - val_loss: 1.2455\n",
      "Epoch 150/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6923 - loss: 1.1801 - val_accuracy: 0.6867 - val_loss: 1.2415\n",
      "Epoch 151/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6923 - loss: 1.1765 - val_accuracy: 0.6877 - val_loss: 1.2375\n",
      "Epoch 152/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.6947 - loss: 1.1617 - val_accuracy: 0.6886 - val_loss: 1.2336\n",
      "Epoch 153/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6979 - loss: 1.1568 - val_accuracy: 0.6897 - val_loss: 1.2299\n",
      "Epoch 154/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.6962 - loss: 1.1559 - val_accuracy: 0.6910 - val_loss: 1.2262\n",
      "Epoch 155/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.6965 - loss: 1.1561 - val_accuracy: 0.6914 - val_loss: 1.2231\n",
      "Epoch 156/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7008 - loss: 1.1456 - val_accuracy: 0.6921 - val_loss: 1.2184\n",
      "Epoch 157/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7022 - loss: 1.1388 - val_accuracy: 0.6936 - val_loss: 1.2142\n",
      "Epoch 158/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.7010 - loss: 1.1403 - val_accuracy: 0.6946 - val_loss: 1.2108\n",
      "Epoch 159/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7015 - loss: 1.1374 - val_accuracy: 0.6955 - val_loss: 1.2069\n",
      "Epoch 160/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7042 - loss: 1.1291 - val_accuracy: 0.6963 - val_loss: 1.2043\n",
      "Epoch 161/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7037 - loss: 1.1289 - val_accuracy: 0.6970 - val_loss: 1.2006\n",
      "Epoch 162/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7030 - loss: 1.1327 - val_accuracy: 0.6976 - val_loss: 1.1969\n",
      "Epoch 163/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7070 - loss: 1.1132 - val_accuracy: 0.6989 - val_loss: 1.1940\n",
      "Epoch 164/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7076 - loss: 1.1166 - val_accuracy: 0.6996 - val_loss: 1.1896\n",
      "Epoch 165/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7061 - loss: 1.1157 - val_accuracy: 0.7006 - val_loss: 1.1856\n",
      "Epoch 166/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7072 - loss: 1.1134 - val_accuracy: 0.7012 - val_loss: 1.1830\n",
      "Epoch 167/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7081 - loss: 1.1133 - val_accuracy: 0.7018 - val_loss: 1.1794\n",
      "Epoch 168/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7101 - loss: 1.0994 - val_accuracy: 0.7021 - val_loss: 1.1764\n",
      "Epoch 169/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7110 - loss: 1.1045 - val_accuracy: 0.7037 - val_loss: 1.1729\n",
      "Epoch 170/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7123 - loss: 1.0960 - val_accuracy: 0.7043 - val_loss: 1.1691\n",
      "Epoch 171/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.7115 - loss: 1.0952 - val_accuracy: 0.7048 - val_loss: 1.1663\n",
      "Epoch 172/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7143 - loss: 1.0889 - val_accuracy: 0.7056 - val_loss: 1.1631\n",
      "Epoch 173/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7141 - loss: 1.0887 - val_accuracy: 0.7065 - val_loss: 1.1604\n",
      "Epoch 174/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7151 - loss: 1.0832 - val_accuracy: 0.7075 - val_loss: 1.1567\n",
      "Epoch 175/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7152 - loss: 1.0796 - val_accuracy: 0.7082 - val_loss: 1.1532\n",
      "Epoch 176/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7174 - loss: 1.0725 - val_accuracy: 0.7090 - val_loss: 1.1502\n",
      "Epoch 177/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7166 - loss: 1.0738 - val_accuracy: 0.7097 - val_loss: 1.1465\n",
      "Epoch 178/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7184 - loss: 1.0680 - val_accuracy: 0.7104 - val_loss: 1.1443\n",
      "Epoch 179/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7185 - loss: 1.0669 - val_accuracy: 0.7110 - val_loss: 1.1412\n",
      "Epoch 180/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7182 - loss: 1.0675 - val_accuracy: 0.7115 - val_loss: 1.1387\n",
      "Epoch 181/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7190 - loss: 1.0657 - val_accuracy: 0.7121 - val_loss: 1.1356\n",
      "Epoch 182/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7221 - loss: 1.0601 - val_accuracy: 0.7129 - val_loss: 1.1331\n",
      "Epoch 183/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7219 - loss: 1.0534 - val_accuracy: 0.7139 - val_loss: 1.1304\n",
      "Epoch 184/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7225 - loss: 1.0529 - val_accuracy: 0.7146 - val_loss: 1.1266\n",
      "Epoch 185/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7235 - loss: 1.0519 - val_accuracy: 0.7145 - val_loss: 1.1249\n",
      "Epoch 186/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7242 - loss: 1.0490 - val_accuracy: 0.7154 - val_loss: 1.1230\n",
      "Epoch 187/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7244 - loss: 1.0442 - val_accuracy: 0.7158 - val_loss: 1.1195\n",
      "Epoch 188/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7272 - loss: 1.0401 - val_accuracy: 0.7168 - val_loss: 1.1168\n",
      "Epoch 189/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 1.0418 - val_accuracy: 0.7172 - val_loss: 1.1140\n",
      "Epoch 190/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7272 - loss: 1.0355 - val_accuracy: 0.7179 - val_loss: 1.1123\n",
      "Epoch 191/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7293 - loss: 1.0287 - val_accuracy: 0.7187 - val_loss: 1.1096\n",
      "Epoch 192/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7289 - loss: 1.0310 - val_accuracy: 0.7188 - val_loss: 1.1061\n",
      "Epoch 193/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7294 - loss: 1.0247 - val_accuracy: 0.7197 - val_loss: 1.1044\n",
      "Epoch 194/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7280 - loss: 1.0295 - val_accuracy: 0.7208 - val_loss: 1.1011\n",
      "Epoch 195/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7314 - loss: 1.0202 - val_accuracy: 0.7209 - val_loss: 1.0986\n",
      "Epoch 196/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.7294 - loss: 1.0213 - val_accuracy: 0.7220 - val_loss: 1.0962\n",
      "Epoch 197/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 102ms/step - accuracy: 0.7319 - loss: 1.0175 - val_accuracy: 0.7224 - val_loss: 1.0935\n",
      "Epoch 198/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7314 - loss: 1.0166 - val_accuracy: 0.7230 - val_loss: 1.0914\n",
      "Epoch 199/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7315 - loss: 1.0220 - val_accuracy: 0.7233 - val_loss: 1.0886\n",
      "Epoch 200/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7349 - loss: 1.0067 - val_accuracy: 0.7240 - val_loss: 1.0864\n",
      "Epoch 201/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7343 - loss: 1.0073 - val_accuracy: 0.7241 - val_loss: 1.0840\n",
      "Epoch 202/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7340 - loss: 1.0103 - val_accuracy: 0.7246 - val_loss: 1.0820\n",
      "Epoch 203/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7350 - loss: 1.0060 - val_accuracy: 0.7257 - val_loss: 1.0798\n",
      "Epoch 204/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7357 - loss: 1.0003 - val_accuracy: 0.7260 - val_loss: 1.0770\n",
      "Epoch 205/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7371 - loss: 0.9996 - val_accuracy: 0.7261 - val_loss: 1.0751\n",
      "Epoch 206/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7370 - loss: 0.9984 - val_accuracy: 0.7271 - val_loss: 1.0726\n",
      "Epoch 207/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7361 - loss: 0.9963 - val_accuracy: 0.7274 - val_loss: 1.0705\n",
      "Epoch 208/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7352 - loss: 0.9981 - val_accuracy: 0.7282 - val_loss: 1.0682\n",
      "Epoch 209/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 106ms/step - accuracy: 0.7387 - loss: 0.9879 - val_accuracy: 0.7278 - val_loss: 1.0659\n",
      "Epoch 210/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 105ms/step - accuracy: 0.7372 - loss: 0.9957 - val_accuracy: 0.7290 - val_loss: 1.0633\n",
      "Epoch 211/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7396 - loss: 0.9888 - val_accuracy: 0.7293 - val_loss: 1.0608\n",
      "Epoch 212/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7393 - loss: 0.9882 - val_accuracy: 0.7296 - val_loss: 1.0591\n",
      "Epoch 213/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 105ms/step - accuracy: 0.7413 - loss: 0.9782 - val_accuracy: 0.7301 - val_loss: 1.0570\n",
      "Epoch 214/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 106ms/step - accuracy: 0.7413 - loss: 0.9793 - val_accuracy: 0.7308 - val_loss: 1.0552\n",
      "Epoch 215/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7434 - loss: 0.9715 - val_accuracy: 0.7312 - val_loss: 1.0534\n",
      "Epoch 216/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7419 - loss: 0.9779 - val_accuracy: 0.7318 - val_loss: 1.0512\n",
      "Epoch 217/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7437 - loss: 0.9678 - val_accuracy: 0.7317 - val_loss: 1.0491\n",
      "Epoch 218/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7438 - loss: 0.9705 - val_accuracy: 0.7323 - val_loss: 1.0471\n",
      "Epoch 219/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1432s\u001b[0m 789ms/step - accuracy: 0.7442 - loss: 0.9671 - val_accuracy: 0.7330 - val_loss: 1.0447\n",
      "Epoch 220/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 110ms/step - accuracy: 0.7454 - loss: 0.9630 - val_accuracy: 0.7332 - val_loss: 1.0432\n",
      "Epoch 221/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7447 - loss: 0.9646 - val_accuracy: 0.7337 - val_loss: 1.0415\n",
      "Epoch 222/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7452 - loss: 0.9601 - val_accuracy: 0.7338 - val_loss: 1.0391\n",
      "Epoch 223/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7463 - loss: 0.9654 - val_accuracy: 0.7349 - val_loss: 1.0369\n",
      "Epoch 224/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 104ms/step - accuracy: 0.7469 - loss: 0.9569 - val_accuracy: 0.7353 - val_loss: 1.0343\n",
      "Epoch 225/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7464 - loss: 0.9556 - val_accuracy: 0.7356 - val_loss: 1.0327\n",
      "Epoch 226/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.7473 - loss: 0.9533 - val_accuracy: 0.7356 - val_loss: 1.0316\n",
      "Epoch 227/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7487 - loss: 0.9471 - val_accuracy: 0.7365 - val_loss: 1.0290\n",
      "Epoch 228/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7486 - loss: 0.9476 - val_accuracy: 0.7368 - val_loss: 1.0277\n",
      "Epoch 229/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7499 - loss: 0.9445 - val_accuracy: 0.7375 - val_loss: 1.0255\n",
      "Epoch 230/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7506 - loss: 0.9440 - val_accuracy: 0.7375 - val_loss: 1.0238\n",
      "Epoch 231/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7506 - loss: 0.9414 - val_accuracy: 0.7381 - val_loss: 1.0222\n",
      "Epoch 232/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7494 - loss: 0.9449 - val_accuracy: 0.7390 - val_loss: 1.0200\n",
      "Epoch 233/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.7522 - loss: 0.9344 - val_accuracy: 0.7395 - val_loss: 1.0172\n",
      "Epoch 234/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7520 - loss: 0.9388 - val_accuracy: 0.7398 - val_loss: 1.0162\n",
      "Epoch 235/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 104ms/step - accuracy: 0.7526 - loss: 0.9342 - val_accuracy: 0.7404 - val_loss: 1.0140\n",
      "Epoch 236/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7524 - loss: 0.9368 - val_accuracy: 0.7403 - val_loss: 1.0126\n",
      "Epoch 237/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7514 - loss: 0.9323 - val_accuracy: 0.7409 - val_loss: 1.0115\n",
      "Epoch 238/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7528 - loss: 0.9323 - val_accuracy: 0.7413 - val_loss: 1.0095\n",
      "Epoch 239/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 105ms/step - accuracy: 0.7523 - loss: 0.9382 - val_accuracy: 0.7415 - val_loss: 1.0078\n",
      "Epoch 240/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 105ms/step - accuracy: 0.7538 - loss: 0.9280 - val_accuracy: 0.7418 - val_loss: 1.0060\n",
      "Epoch 241/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 105ms/step - accuracy: 0.7546 - loss: 0.9289 - val_accuracy: 0.7425 - val_loss: 1.0045\n",
      "Epoch 242/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 105ms/step - accuracy: 0.7537 - loss: 0.9264 - val_accuracy: 0.7432 - val_loss: 1.0021\n",
      "Epoch 243/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.7548 - loss: 0.9199 - val_accuracy: 0.7432 - val_loss: 1.0009\n",
      "Epoch 244/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7565 - loss: 0.9164 - val_accuracy: 0.7438 - val_loss: 0.9995\n",
      "Epoch 245/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7559 - loss: 0.9214 - val_accuracy: 0.7441 - val_loss: 0.9975\n",
      "Epoch 246/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7582 - loss: 0.9143 - val_accuracy: 0.7445 - val_loss: 0.9959\n",
      "Epoch 247/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 105ms/step - accuracy: 0.7557 - loss: 0.9208 - val_accuracy: 0.7446 - val_loss: 0.9944\n",
      "Epoch 248/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 104ms/step - accuracy: 0.7572 - loss: 0.9150 - val_accuracy: 0.7453 - val_loss: 0.9928\n",
      "Epoch 249/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 105ms/step - accuracy: 0.7584 - loss: 0.9080 - val_accuracy: 0.7452 - val_loss: 0.9913\n",
      "Epoch 250/250\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 105ms/step - accuracy: 0.7595 - loss: 0.9121 - val_accuracy: 0.7456 - val_loss: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b1ec0f3e90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5431498289108276\n",
      "Train accuracy: 0.8624534606933594\n",
      "Test loss: 0.9898993968963623\n",
      "Test accuracy: 0.7455573678016663\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1205/1205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step\n",
      "Total de imágenes en el conjunto de prueba: 38547\n",
      "Predicciones correctas: 28739\n",
      "Precisión en el conjunto de prueba: 74.56%\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en todo el conjunto de prueba\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Obtener las clases predichas\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obtener las clases verdaderas\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Contar cuántas predicciones son correctas\n",
    "correct_predictions = np.sum(predicted_classes == true_classes)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "\n",
    "print(f\"Total de imágenes en el conjunto de prueba: {len(y_test)}\")\n",
    "print(f\"Predicciones correctas: {correct_predictions}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('kanji_model_250_epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
