{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on MNIST CNN from Keras' examples: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py (MIT License)\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "https://paperswithcode.com/dataset/kuzushiji-49\n",
    "https://github.com/rois-codh/kmnist\n",
    "\n",
    "['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
    "'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
    "'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
    "'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz'],\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 49\n",
    "epochs = 100\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "\n",
    "# Load the data\n",
    "x_train = load('k49-train-imgs.npz')\n",
    "x_test = load('k49-test-imgs.npz')\n",
    "y_train = load('k49-train-labels.npz')\n",
    "y_test = load('k49-test-labels.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232365 train samples, 38547 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('{} train samples, {} test samples'.format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 110ms/step - accuracy: 0.0380 - loss: 3.8734 - val_accuracy: 0.1168 - val_loss: 3.8023\n",
      "Epoch 2/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.0864 - loss: 3.7688 - val_accuracy: 0.2120 - val_loss: 3.6500\n",
      "Epoch 3/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.1419 - loss: 3.5919 - val_accuracy: 0.2850 - val_loss: 3.4278\n",
      "Epoch 4/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.2015 - loss: 3.3644 - val_accuracy: 0.3176 - val_loss: 3.1895\n",
      "Epoch 5/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 98ms/step - accuracy: 0.2534 - loss: 3.1336 - val_accuracy: 0.3474 - val_loss: 2.9903\n",
      "Epoch 6/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 98ms/step - accuracy: 0.2909 - loss: 2.9554 - val_accuracy: 0.3697 - val_loss: 2.8376\n",
      "Epoch 7/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3223 - loss: 2.8077 - val_accuracy: 0.3878 - val_loss: 2.7188\n",
      "Epoch 8/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3455 - loss: 2.6981 - val_accuracy: 0.3993 - val_loss: 2.6225\n",
      "Epoch 9/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.3659 - loss: 2.6018 - val_accuracy: 0.4126 - val_loss: 2.5437\n",
      "Epoch 10/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 97ms/step - accuracy: 0.3793 - loss: 2.5292 - val_accuracy: 0.4246 - val_loss: 2.4777\n",
      "Epoch 11/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.3962 - loss: 2.4579 - val_accuracy: 0.4356 - val_loss: 2.4202\n",
      "Epoch 12/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4041 - loss: 2.4125 - val_accuracy: 0.4451 - val_loss: 2.3695\n",
      "Epoch 13/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4177 - loss: 2.3600 - val_accuracy: 0.4533 - val_loss: 2.3240\n",
      "Epoch 14/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 98ms/step - accuracy: 0.4261 - loss: 2.3228 - val_accuracy: 0.4612 - val_loss: 2.2858\n",
      "Epoch 15/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4350 - loss: 2.2742 - val_accuracy: 0.4674 - val_loss: 2.2495\n",
      "Epoch 16/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.4418 - loss: 2.2458 - val_accuracy: 0.4743 - val_loss: 2.2184\n",
      "Epoch 17/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.4512 - loss: 2.2154 - val_accuracy: 0.4791 - val_loss: 2.1911\n",
      "Epoch 18/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 99ms/step - accuracy: 0.4553 - loss: 2.1920 - val_accuracy: 0.4839 - val_loss: 2.1665\n",
      "Epoch 19/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 98ms/step - accuracy: 0.4603 - loss: 2.1641 - val_accuracy: 0.4904 - val_loss: 2.1418\n",
      "Epoch 20/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 98ms/step - accuracy: 0.4656 - loss: 2.1412 - val_accuracy: 0.4939 - val_loss: 2.1198\n",
      "Epoch 21/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.4712 - loss: 2.1127 - val_accuracy: 0.4980 - val_loss: 2.0996\n",
      "Epoch 22/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 109ms/step - accuracy: 0.4763 - loss: 2.0940 - val_accuracy: 0.5013 - val_loss: 2.0804\n",
      "Epoch 23/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 112ms/step - accuracy: 0.4829 - loss: 2.0674 - val_accuracy: 0.5046 - val_loss: 2.0629\n",
      "Epoch 24/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 114ms/step - accuracy: 0.4861 - loss: 2.0556 - val_accuracy: 0.5081 - val_loss: 2.0458\n",
      "Epoch 25/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 110ms/step - accuracy: 0.4884 - loss: 2.0418 - val_accuracy: 0.5113 - val_loss: 2.0313\n",
      "Epoch 26/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 108ms/step - accuracy: 0.4936 - loss: 2.0213 - val_accuracy: 0.5138 - val_loss: 2.0173\n",
      "Epoch 27/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 110ms/step - accuracy: 0.4962 - loss: 2.0112 - val_accuracy: 0.5152 - val_loss: 2.0018\n",
      "Epoch 28/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 109ms/step - accuracy: 0.4964 - loss: 2.0069 - val_accuracy: 0.5190 - val_loss: 1.9876\n",
      "Epoch 29/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 109ms/step - accuracy: 0.5040 - loss: 1.9811 - val_accuracy: 0.5223 - val_loss: 1.9757\n",
      "Epoch 30/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 110ms/step - accuracy: 0.5051 - loss: 1.9717 - val_accuracy: 0.5250 - val_loss: 1.9632\n",
      "Epoch 31/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 108ms/step - accuracy: 0.5076 - loss: 1.9570 - val_accuracy: 0.5275 - val_loss: 1.9506\n",
      "Epoch 32/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 112ms/step - accuracy: 0.5117 - loss: 1.9436 - val_accuracy: 0.5301 - val_loss: 1.9392\n",
      "Epoch 33/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.5148 - loss: 1.9312 - val_accuracy: 0.5329 - val_loss: 1.9281\n",
      "Epoch 34/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 100ms/step - accuracy: 0.5183 - loss: 1.9177 - val_accuracy: 0.5347 - val_loss: 1.9192\n",
      "Epoch 35/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.5212 - loss: 1.9021 - val_accuracy: 0.5373 - val_loss: 1.9073\n",
      "Epoch 36/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 106ms/step - accuracy: 0.5236 - loss: 1.8983 - val_accuracy: 0.5397 - val_loss: 1.8964\n",
      "Epoch 37/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 108ms/step - accuracy: 0.5233 - loss: 1.8951 - val_accuracy: 0.5419 - val_loss: 1.8864\n",
      "Epoch 38/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.5277 - loss: 1.8728 - val_accuracy: 0.5432 - val_loss: 1.8768\n",
      "Epoch 39/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 108ms/step - accuracy: 0.5290 - loss: 1.8671 - val_accuracy: 0.5462 - val_loss: 1.8683\n",
      "Epoch 40/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.5320 - loss: 1.8547 - val_accuracy: 0.5476 - val_loss: 1.8587\n",
      "Epoch 41/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.5333 - loss: 1.8471 - val_accuracy: 0.5503 - val_loss: 1.8486\n",
      "Epoch 42/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 102ms/step - accuracy: 0.5367 - loss: 1.8330 - val_accuracy: 0.5525 - val_loss: 1.8392\n",
      "Epoch 43/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 104ms/step - accuracy: 0.5371 - loss: 1.8289 - val_accuracy: 0.5539 - val_loss: 1.8303\n",
      "Epoch 44/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5415 - loss: 1.8126 - val_accuracy: 0.5556 - val_loss: 1.8225\n",
      "Epoch 45/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 103ms/step - accuracy: 0.5428 - loss: 1.8039 - val_accuracy: 0.5581 - val_loss: 1.8141\n",
      "Epoch 46/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 107ms/step - accuracy: 0.5462 - loss: 1.7938 - val_accuracy: 0.5599 - val_loss: 1.8071\n",
      "Epoch 47/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.5486 - loss: 1.7844 - val_accuracy: 0.5617 - val_loss: 1.7978\n",
      "Epoch 48/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 101ms/step - accuracy: 0.5488 - loss: 1.7796 - val_accuracy: 0.5638 - val_loss: 1.7894\n",
      "Epoch 49/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 106ms/step - accuracy: 0.5517 - loss: 1.7646 - val_accuracy: 0.5654 - val_loss: 1.7802\n",
      "Epoch 50/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 100ms/step - accuracy: 0.5552 - loss: 1.7565 - val_accuracy: 0.5671 - val_loss: 1.7724\n",
      "Epoch 51/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.5591 - loss: 1.7430 - val_accuracy: 0.5684 - val_loss: 1.7644\n",
      "Epoch 52/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 101ms/step - accuracy: 0.5575 - loss: 1.7396 - val_accuracy: 0.5701 - val_loss: 1.7589\n",
      "Epoch 53/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5609 - loss: 1.7279 - val_accuracy: 0.5723 - val_loss: 1.7484\n",
      "Epoch 54/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 100ms/step - accuracy: 0.5640 - loss: 1.7155 - val_accuracy: 0.5740 - val_loss: 1.7417\n",
      "Epoch 55/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5653 - loss: 1.7151 - val_accuracy: 0.5760 - val_loss: 1.7347\n",
      "Epoch 56/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 100ms/step - accuracy: 0.5670 - loss: 1.7046 - val_accuracy: 0.5784 - val_loss: 1.7262\n",
      "Epoch 57/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5693 - loss: 1.6951 - val_accuracy: 0.5802 - val_loss: 1.7172\n",
      "Epoch 58/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 99ms/step - accuracy: 0.5713 - loss: 1.6857 - val_accuracy: 0.5822 - val_loss: 1.7105\n",
      "Epoch 59/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 115ms/step - accuracy: 0.5723 - loss: 1.6795 - val_accuracy: 0.5830 - val_loss: 1.7026\n",
      "Epoch 60/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 119ms/step - accuracy: 0.5747 - loss: 1.6698 - val_accuracy: 0.5851 - val_loss: 1.6948\n",
      "Epoch 61/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 122ms/step - accuracy: 0.5760 - loss: 1.6628 - val_accuracy: 0.5870 - val_loss: 1.6871\n",
      "Epoch 62/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 119ms/step - accuracy: 0.5807 - loss: 1.6467 - val_accuracy: 0.5886 - val_loss: 1.6796\n",
      "Epoch 63/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 116ms/step - accuracy: 0.5817 - loss: 1.6430 - val_accuracy: 0.5904 - val_loss: 1.6728\n",
      "Epoch 64/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 119ms/step - accuracy: 0.5843 - loss: 1.6310 - val_accuracy: 0.5916 - val_loss: 1.6657\n",
      "Epoch 65/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 120ms/step - accuracy: 0.5845 - loss: 1.6280 - val_accuracy: 0.5934 - val_loss: 1.6593\n",
      "Epoch 66/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 121ms/step - accuracy: 0.5862 - loss: 1.6180 - val_accuracy: 0.5947 - val_loss: 1.6507\n",
      "Epoch 67/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 116ms/step - accuracy: 0.5889 - loss: 1.6139 - val_accuracy: 0.5967 - val_loss: 1.6424\n",
      "Epoch 68/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 118ms/step - accuracy: 0.5909 - loss: 1.6006 - val_accuracy: 0.5982 - val_loss: 1.6358\n",
      "Epoch 69/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 111ms/step - accuracy: 0.5942 - loss: 1.5919 - val_accuracy: 0.6008 - val_loss: 1.6288\n",
      "Epoch 70/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 122ms/step - accuracy: 0.5954 - loss: 1.5831 - val_accuracy: 0.6017 - val_loss: 1.6212\n",
      "Epoch 71/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 123ms/step - accuracy: 0.5943 - loss: 1.5830 - val_accuracy: 0.6031 - val_loss: 1.6142\n",
      "Epoch 72/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 130ms/step - accuracy: 0.5998 - loss: 1.5649 - val_accuracy: 0.6048 - val_loss: 1.6058\n",
      "Epoch 73/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 131ms/step - accuracy: 0.5999 - loss: 1.5604 - val_accuracy: 0.6061 - val_loss: 1.6002\n",
      "Epoch 74/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 125ms/step - accuracy: 0.6045 - loss: 1.5476 - val_accuracy: 0.6083 - val_loss: 1.5925\n",
      "Epoch 75/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 124ms/step - accuracy: 0.6064 - loss: 1.5366 - val_accuracy: 0.6097 - val_loss: 1.5857\n",
      "Epoch 76/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 116ms/step - accuracy: 0.6079 - loss: 1.5346 - val_accuracy: 0.6112 - val_loss: 1.5784\n",
      "Epoch 77/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 119ms/step - accuracy: 0.6089 - loss: 1.5297 - val_accuracy: 0.6126 - val_loss: 1.5714\n",
      "Epoch 78/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 120ms/step - accuracy: 0.6106 - loss: 1.5255 - val_accuracy: 0.6144 - val_loss: 1.5640\n",
      "Epoch 79/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 122ms/step - accuracy: 0.6155 - loss: 1.5028 - val_accuracy: 0.6155 - val_loss: 1.5569\n",
      "Epoch 80/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 116ms/step - accuracy: 0.6152 - loss: 1.5006 - val_accuracy: 0.6173 - val_loss: 1.5490\n",
      "Epoch 81/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 112ms/step - accuracy: 0.6171 - loss: 1.4948 - val_accuracy: 0.6195 - val_loss: 1.5417\n",
      "Epoch 82/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 114ms/step - accuracy: 0.6192 - loss: 1.4887 - val_accuracy: 0.6209 - val_loss: 1.5352\n",
      "Epoch 83/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 111ms/step - accuracy: 0.6217 - loss: 1.4793 - val_accuracy: 0.6225 - val_loss: 1.5290\n",
      "Epoch 84/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 103ms/step - accuracy: 0.6223 - loss: 1.4703 - val_accuracy: 0.6235 - val_loss: 1.5214\n",
      "Epoch 85/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 103ms/step - accuracy: 0.6233 - loss: 1.4649 - val_accuracy: 0.6246 - val_loss: 1.5152\n",
      "Epoch 86/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 92ms/step - accuracy: 0.6276 - loss: 1.4482 - val_accuracy: 0.6268 - val_loss: 1.5079\n",
      "Epoch 87/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 90ms/step - accuracy: 0.6291 - loss: 1.4451 - val_accuracy: 0.6286 - val_loss: 1.5019\n",
      "Epoch 88/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6304 - loss: 1.4361 - val_accuracy: 0.6302 - val_loss: 1.4949\n",
      "Epoch 89/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6319 - loss: 1.4278 - val_accuracy: 0.6316 - val_loss: 1.4876\n",
      "Epoch 90/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6341 - loss: 1.4222 - val_accuracy: 0.6331 - val_loss: 1.4811\n",
      "Epoch 91/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6349 - loss: 1.4180 - val_accuracy: 0.6347 - val_loss: 1.4746\n",
      "Epoch 92/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6371 - loss: 1.4097 - val_accuracy: 0.6366 - val_loss: 1.4683\n",
      "Epoch 93/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6374 - loss: 1.4099 - val_accuracy: 0.6378 - val_loss: 1.4616\n",
      "Epoch 94/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 90ms/step - accuracy: 0.6404 - loss: 1.3973 - val_accuracy: 0.6391 - val_loss: 1.4546\n",
      "Epoch 95/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6414 - loss: 1.3918 - val_accuracy: 0.6411 - val_loss: 1.4478\n",
      "Epoch 96/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6432 - loss: 1.3870 - val_accuracy: 0.6427 - val_loss: 1.4412\n",
      "Epoch 97/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6458 - loss: 1.3761 - val_accuracy: 0.6438 - val_loss: 1.4356\n",
      "Epoch 98/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6480 - loss: 1.3676 - val_accuracy: 0.6455 - val_loss: 1.4294\n",
      "Epoch 99/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 89ms/step - accuracy: 0.6477 - loss: 1.3677 - val_accuracy: 0.6464 - val_loss: 1.4228\n",
      "Epoch 100/100\n",
      "\u001b[1m1816/1816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 89ms/step - accuracy: 0.6502 - loss: 1.3573 - val_accuracy: 0.6480 - val_loss: 1.4172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b212f37830>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9172776341438293\n",
      "Train accuracy: 0.7763518691062927\n",
      "Test loss: 1.4172379970550537\n",
      "Test accuracy: 0.6479881405830383\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1205/1205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Total de imágenes en el conjunto de prueba: 38547\n",
      "Predicciones correctas: 24978\n",
      "Precisión en el conjunto de prueba: 64.80%\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en todo el conjunto de prueba\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Obtener las clases predichas\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obtener las clases verdaderas\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Contar cuántas predicciones son correctas\n",
    "correct_predictions = np.sum(predicted_classes == true_classes)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "\n",
    "print(f\"Total de imágenes en el conjunto de prueba: {len(y_test)}\")\n",
    "print(f\"Predicciones correctas: {correct_predictions}\")\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kanji_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
