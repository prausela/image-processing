{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm  # Importar tqdm para la barra de progreso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"martingrzzler/kanjis2radicals\")\n",
    "\"\"\" Item in ds['train']\n",
    " Dataset({\n",
    "    features: ['kanji_image', 'meta'],\n",
    "    num_rows: 2027\n",
    "})\n",
    "\n",
    "{'kanji_image': Image(mode=None, decode=True, id=None), \n",
    " 'meta': {'id': Value(dtype='int32', id=None), \n",
    "          'characters': Value(dtype='string', id=None), \n",
    "          'meanings': Value(dtype='string', id=None), \n",
    "          'radicals': Sequence(feature={'characters': Value(dtype='string', id=None), \n",
    "                                        'id': Value(dtype='int32', id=None), \n",
    "                                        'slug': Value(dtype='string', id=None)\n",
    "                                        }, length=-1, id=None)\n",
    "         }\n",
    "}\n",
    "\"\"\"\n",
    "# Split the dataset into train and test (80-20 split by default)\n",
    "ds_split = ds['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "# Access the train and test subsets\n",
    "ds_train = ds_split['train']\n",
    "ds_test = ds_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique radicals: 478\n",
      "Sorted unique radicals: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 8761, 8762, 8763, 8764, 8765, 8766, 8767, 8768, 8769, 8770, 8771, 8772, 8773, 8774, 8775, 8776, 8777, 8778, 8779, 8780, 8781, 8782, 8783, 8784, 8785, 8787, 8788, 8790, 8792, 8793, 8794, 8796, 8797, 8798, 8799, 8819, 8820, 8821, 8822, 8823, 8824, 8825, 8826, 8827, 8828, 8829, 8830, 8831, 8832]\n"
     ]
    }
   ],
   "source": [
    "# Extract all unique radicals\n",
    "unique_radicals = set()\n",
    "for element in ds['train']:\n",
    "    radical_ids = element['meta']['radicals']['id']\n",
    "    unique_radicals.update(radical_ids)\n",
    "\n",
    "# Sort the unique radicals\n",
    "sorted_unique_radicals = sorted(unique_radicals)\n",
    "\n",
    "# Count total unique radicals\n",
    "total_unique_radicals = len(sorted_unique_radicals)\n",
    "\n",
    "print(f\"Total unique radicals: {total_unique_radicals}\")\n",
    "print(f\"Sorted unique radicals: {sorted_unique_radicals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(ds):\n",
    "    # Crear un mapeo de radicales únicos a índices\n",
    "    radical_to_index = {radical: idx for idx, radical in enumerate(unique_radicals)}\n",
    "\n",
    "    # Transformar los identificadores de radicales en vectores binarios\n",
    "    def generate_label_vector(radical_ids, total_radicals):\n",
    "        label_vector = [0] * total_radicals\n",
    "        for radical_id in radical_ids:\n",
    "            if radical_id in radical_to_index:\n",
    "                label_vector[radical_to_index[radical_id]] = 1\n",
    "        return label_vector\n",
    "\n",
    "    # Generar labels para el dataset de entrenamiento\n",
    "    total_unique_radicals = len(unique_radicals)\n",
    "    labels = []\n",
    "\n",
    "    for element in ds:\n",
    "        radical_ids = element['meta']['radicals']['id']\n",
    "        label_vector = generate_label_vector(radical_ids, total_unique_radicals)\n",
    "        labels.append(label_vector)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = label_vector(ds_train)\n",
    "test_labels = label_vector(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),         # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] for RGB\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(ds_image, ds_label):\n",
    "    # Define a transformation pipeline for the images\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "\n",
    "    for i, _ in enumerate(ds_image):\n",
    "        # Example image path and label (replace with actual paths)\n",
    "        radical_ids = ds_label[i]\n",
    "        \n",
    "        # Load and transform the image\n",
    "        image = ds_image[i]['kanji_image'].convert(\"RGB\")\n",
    "        image_tensor = image_transform(image)\n",
    "        \n",
    "        # Convert radical IDs to tensor\n",
    "        label_tensor = torch.tensor(radical_ids, dtype=torch.long)\n",
    "        \n",
    "        # Append to batch lists\n",
    "        batch_images.append(image_tensor)\n",
    "        batch_labels.append(label_tensor)\n",
    "\n",
    "    # Stack into a batch (list of tensors to tensor batch)\n",
    "    batch_images = torch.stack(batch_images)\n",
    "    batch_labels = torch.nn.utils.rnn.pad_sequence(batch_labels, batch_first=True, padding_value=-1)\n",
    "\n",
    "    print(f\"Batch Images Shape: {batch_images.shape}\")  # [batch_size, channels, height, width]\n",
    "    print(f\"Batch Labels Shape: {batch_labels.shape}\")  # [batch_size, max_seq_len]\n",
    "    return batch_images, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Images Shape: torch.Size([1621, 3, 128, 128])\n",
      "Batch Labels Shape: torch.Size([1621, 478])\n",
      "Batch Images Shape: torch.Size([406, 3, 128, 128])\n",
      "Batch Labels Shape: torch.Size([406, 478])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_img, train_labels = sample_batch(ds_train, train_labels)\n",
    "test_img, test_labels = sample_batch(ds_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the collate_fn to pad sequences and stack the images\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([item[0] for item in batch])  # Stack all images in the batch\n",
    "    labels = [item[1] for item in batch]  # Get the labels (radical IDs) for each image\n",
    "    \n",
    "    # Pad the label sequences\n",
    "    labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-1)\n",
    "    \n",
    "    return images, labels_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KanjiRadicalDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (list): List of file paths to the Kanji images.\n",
    "            labels (list): List of corresponding radical ID lists for each image.\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary with 'image' and 'label' tensors.\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and testing\n",
    "train_dataset = KanjiRadicalDataset(images=train_img, labels=train_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=lambda batch: collate_fn(batch))\n",
    "\n",
    "test_dataset = KanjiRadicalDataset(images=test_img, labels=test_labels)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True, collate_fn=lambda batch: collate_fn(batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block_nested(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(conv_block_nested, self).__init__()\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
    "        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        output = self.activation(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nested_UNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(Nested_UNet, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])\n",
    "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])\n",
    "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])\n",
    "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])\n",
    "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])\n",
    "\n",
    "        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])\n",
    "        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])\n",
    "        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])\n",
    "        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])\n",
    "\n",
    "        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])\n",
    "        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])\n",
    "\n",
    "        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])\n",
    "        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])\n",
    "\n",
    "        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(filters[0], out_ch, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n",
    "\n",
    "        output = self.final(x0_4)\n",
    "        output = output.view(output.size(0), -1)  # [batch_size, out_ch]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 102/102 [52:46<00:00, 31.05s/it, Loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.3468477936352001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 102/102 [51:37<00:00, 30.37s/it, Loss=1.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 1.2750413417816162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcular el peso basado en la proporción de ceros y unos\n",
    "# Calcular pos_weight basado en el dataset (num_negatives / num_positives)\n",
    "# Convertir las etiquetas en un array de numpy para facilidad de conteo\n",
    "labels_array = np.array(train_labels)  # Asegúrate de que train_labels es una lista o array-like\n",
    "\n",
    "# Contar la cantidad de ceros y unos\n",
    "num_negatives = np.sum(labels_array == 0)  # Cantidad de ceros\n",
    "num_positives = np.sum(labels_array == 1)  # Cantidad de unos\n",
    "\n",
    "pos_weight = torch.tensor([num_negatives / num_positives])\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "num_radicals = 478  # Total unique radicals in the dataset\n",
    "model = Nested_UNet(3, num_radicals)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Multi-label classification con balance\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(2):  # Número de epochs\n",
    "    model.train()\n",
    "    epoch_loss = 0  # Pérdida acumulada por epoch\n",
    "\n",
    "    # Barra de progreso para batches\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for batch in pbar:\n",
    "            images, targets = batch  # Images: [batch_size, 3, 128, 128], Targets: [batch_size, num_radicals]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(images)  # Output: [batch_size, num_radicals]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, targets.float())  # Convertir targets a float\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": loss.item()})  # Actualizar barra de progreso con pérdida actual\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {epoch_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación con ajuste de threshold\n",
    "threshold = 0.7  # Ajustar el umbral para clasificar correctamente los unos\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:  # test_loader contiene los datos de validación\n",
    "        images, targets = batch\n",
    "        \n",
    "        raw_outputs = model(images)  # Predicciones en bruto\n",
    "        predictions = (torch.sigmoid(raw_outputs) > threshold).float()  # Aplicar umbral\n",
    "        \n",
    "        all_predictions.append(predictions.cpu())  # Guardar predicciones\n",
    "        all_targets.append(targets.cpu())          # Guardar objetivos reales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0062, Recall: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas adicionales (F1 Score, Recall)\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "all_predictions = torch.cat(all_predictions).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "f1 = f1_score(all_targets, all_predictions, average=\"macro\")\n",
    "recall = recall_score(all_targets, all_predictions, average=\"macro\")\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_targets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
