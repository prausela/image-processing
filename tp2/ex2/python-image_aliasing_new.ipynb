{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_aliasing_new.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fft as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo\n",
    "skvideo.setFFmpegPath(\"C:/Users/74005/Downloads/ffmpeg-20210728-0068b3d0f0-win64-shared/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos `write_video` para escribir una secuencia de frames en un archivo de video. Esta función ajusta el tamaño de cada frame para que todos tengan el mismo tamaño, rellenando con ceros si es necesario, y luego los escribe en un archivo de video utilizando la biblioteca skvideo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_video(file_path, frames):\n",
    "    # Calculate the maximum height and width of all frames\n",
    "    max_height = max(frame.shape[0] for frame in frames)\n",
    "    max_width = max(frame.shape[1] for frame in frames)\n",
    "\n",
    "    # Pad each frame to the maximum height and width\n",
    "    padded_frames = [np.pad(frame, ((0, max_height - frame.shape[0]), (0, max_width - frame.shape[1]))) for frame in frames]\n",
    "\n",
    "    skvideo.io.vwrite(file_path, np.array(padded_frames, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `centered_affine_transform` se aplica una transformación afín a una imagen, asegurando que la transformación esté centrada. Esta función calcula la nueva posición de la imagen transformada y aplica la transformación para obtener la imagen resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_affine_transform(t, src_im):\n",
    "    \n",
    "    h, w = src_im.shape[:2]\n",
    "\n",
    "    # Extract translation components from the transformation matrix\n",
    "    trans = t[:-1]\n",
    "    inv_t = np.linalg.inv(t)\n",
    "    inv_trans = inv_t[:-1]\n",
    "\n",
    "    # Define source points for the transformation\n",
    "    src_pts = np.float32([[0, 0], [w-1, 0], [0, h-1], [w-1, h-1]])\n",
    "\n",
    "    # Apply the transformation to the source points\n",
    "    dst_pts = cv2.transform(np.array([src_pts]), trans)[0]\n",
    "\n",
    "    # Calculate the bounds of the transformed image\n",
    "    min_x, max_x = np.min(dst_pts[:, 0]), np.max(dst_pts[:, 0])\n",
    "    min_y, max_y = np.min(dst_pts[:, 1]), np.max(dst_pts[:, 1])\n",
    "\n",
    "    # Calculate the size of the transformed image\n",
    "    dst_w, dst_h = int(max_x - min_x + 1), int(max_y - min_y + 1)\n",
    "\n",
    "    # Calculate the center of the transformed image\n",
    "    dst_center = np.float32([[(dst_w-1.0)/2, (dst_h-1.0)/2]])\n",
    "\n",
    "    # Project the center of the transformed image back onto the source image\n",
    "    src_projected_center = cv2.transform(np.array([dst_center]), inv_trans)[0]\n",
    "\n",
    "    # Calculate the translation needed to center the transformation\n",
    "    translation = src_projected_center - np.float32([[(w-1.0)/2, (h-1.0)/2]])\n",
    "\n",
    "    # Update the translation components of the transformation matrix\n",
    "    trans[:, 2] = translation\n",
    "\n",
    "    # Apply the centered affine transformation to the image\n",
    "    return cv2.warpAffine(src_im, trans, (dst_w, dst_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `scale_shrink` definimos las matrices de la transformación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_shrink(xshrink, xsize):\n",
    "    scale_shrink = (xsize - xshrink) / xsize\n",
    "    return np.array([\n",
    "        [scale_shrink, 0, 0],\n",
    "        [0, scale_shrink, 0],\n",
    "        [0, 0, 1],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `scale_boost` creamos una matriz de transformación que vuelve a escalar la imagen a su tamaño original después de haber sido reducida por la función `scale_shrink`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_boost(xsize, f2):\n",
    "    scale_boost = xsize / f2.shape[1]\n",
    "    return np.array([\n",
    "        [scale_boost, 0, 0],\n",
    "        [0, scale_boost, 0],\n",
    "        [0, 0, 1],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el gif e iteramos por los valores de xshrink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "specs = []\n",
    "\n",
    "f = plt.imread('../assets/barbara.gif')\n",
    "\n",
    "for xshrink in range(0, 600, 5):\n",
    "    xsize = f.shape[1]\n",
    "    t1 = scale_shrink(xshrink, xsize)\n",
    "    f2 = centered_affine_transform(t1, f)\n",
    "    t2 = scale_boost(xsize, f2)\n",
    "    f3 = centered_affine_transform(t2, f2)\n",
    "    frames.append(f3[:, :, 0])\n",
    "    Fd = np.log(1 + np.abs(np.fft.fftshift(np.fft.fft2(frames[-1]))))\n",
    "    specs.append(np.uint8(256 * Fd / Fd.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un video con los frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video('aliasing_pics.avi', frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un video con los espectros de frecuencia de las imágenes de cada frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video('aliasing_specs.avi', specs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
